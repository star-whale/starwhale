"use strict";(self.webpackChunkstarwhale_docs=self.webpackChunkstarwhale_docs||[]).push([[466],{3905:function(e,t,a){a.d(t,{Zo:function(){return d},kt:function(){return u}});var n=a(7294);function l(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){l(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,l=function(e,t){if(null==e)return{};var a,n,l={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(l[a]=e[a]);return l}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(l[a]=e[a])}return l}var i=n.createContext({}),c=function(e){var t=n.useContext(i),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},d=function(e){var t=c(e.components);return n.createElement(i.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,l=e.mdxType,r=e.originalType,i=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),m=c(a),u=l,h=m["".concat(i,".").concat(u)]||m[u]||p[u]||r;return a?n.createElement(h,o(o({ref:t},d),{},{components:a})):n.createElement(h,o({ref:t},d))}));function u(e,t){var a=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var r=a.length,o=new Array(r);o[0]=m;var s={};for(var i in t)hasOwnProperty.call(t,i)&&(s[i]=t[i]);s.originalType=e,s.mdxType="string"==typeof e?e:l,o[1]=s;for(var c=2;c<r;c++)o[c]=a[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},6205:function(e,t,a){a.r(t),a.d(t,{assets:function(){return i},contentTitle:function(){return o},default:function(){return p},frontMatter:function(){return r},metadata:function(){return s},toc:function(){return c}});var n=a(3117),l=(a(7294),a(3905));const r={title:"Text Classification on AG News dataset"},o=void 0,s={unversionedId:"tutorials/ag_news",id:"tutorials/ag_news",title:"Text Classification on AG News dataset",description:"This example illustrates how to evaluate a pre-trained text classification model on Starwhale in 6 steps.",source:"@site/docs/tutorials/ag_news.md",sourceDirName:"tutorials",slug:"/tutorials/ag_news",permalink:"/docs/tutorials/ag_news",draft:!1,editUrl:"https://github.com/star-whale/starwhale/tree/main/docs/docs/tutorials/ag_news.md",tags:[],version:"current",frontMatter:{title:"Text Classification on AG News dataset"},sidebar:"mainSidebar",previous:{title:"Audio Classification on Speech Commands Dataset",permalink:"/docs/tutorials/speech"},next:{title:"Image Classification on CIFAR-10",permalink:"/docs/tutorials/cifar10"}},i={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Create a Runtime",id:"create-a-runtime",level:2},{value:"Train the model",id:"train-the-model",level:2},{value:"Slice the test dataset using the Starwhale protocol",id:"slice-the-test-dataset-using-the-starwhale-protocol",level:2},{value:"Implement the inference method and evaluation metrics computing method",id:"implement-the-inference-method-and-evaluation-metrics-computing-method",level:2},{value:"Implement ppl",id:"implement-ppl",level:3},{value:"Implement cmp",id:"implement-cmp",level:3},{value:"Build Runtime, Model, and Dataset",id:"build-runtime-model-and-dataset",level:2},{value:"Build Runtime",id:"build-runtime",level:3},{value:"Build Dataset",id:"build-dataset",level:3},{value:"Write the yaml file",id:"write-the-yaml-file",level:4},{value:"Build Model",id:"build-model",level:3},{value:"Run the evaluation job and see the metrics",id:"run-the-evaluation-job-and-see-the-metrics",level:2},{value:"Evaluate the model on your local standalone instance",id:"evaluate-the-model-on-your-local-standalone-instance",level:3},{value:"Create a job",id:"create-a-job",level:4},{value:"See the metrics",id:"see-the-metrics",level:4},{value:"Evaluate model on a cloud instance",id:"evaluate-model-on-a-cloud-instance",level:3}],d={toc:c};function p(e){let{components:t,...r}=e;return(0,l.kt)("wrapper",(0,n.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("p",null,"This example illustrates how to evaluate a pre-trained text classification model on Starwhale in 6 steps."),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"Create a Runtime"),(0,l.kt)("li",{parentName:"ol"},"Train the model"),(0,l.kt)("li",{parentName:"ol"},"Implement the dataset slicing method"),(0,l.kt)("li",{parentName:"ol"},"Implement the inference method and evaluation metrics computing method"),(0,l.kt)("li",{parentName:"ol"},"Build Runtime, Dataset, and Model"),(0,l.kt)("li",{parentName:"ol"},"Run the evaluation job and see the metrics")),(0,l.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Assume that you have Python3.7 or above installed.")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Clone the Starwhale repo"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/star-whale/starwhale.git\ncd starwhale/example/text_cls_AG_NEWS\n")))),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"\ud83d\udca1 If you are from the mainland of China, we strongly recommend you use a proxy.")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Install ",(0,l.kt)("a",{parentName:"li",href:"/docs/quickstart/standalone"},"Starwhale"))),(0,l.kt)("h2",{id:"create-a-runtime"},"Create a Runtime"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"$ swcli runtime create . --name pytorch_text -m venv --python=3.9 --force --base-image ghcr.io/star-whale/starwhale:0.2.0-alpha.12\n\ud83d\udea7 start to create the runtime environment...\n\ud83c\udf70 run the following command in your shell \ud83c\udf70\n        source ~/code/starwhale/example/text_cls_AG_NEWS/venv/bin/activate\n\ud83d\udc4f python runtime environment is ready to use \ud83c\udf89\n$ source ~/code/starwhale/example/text_cls_AG_NEWS/venv/bin/activate\n(pytorch_text) $  python3 -m pip install -r requirements.txt\n")),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"\ud83d\udca1 make sure python3.9-venv is installed if you choose --python=3.9\n\ud83d\udca1 ",(0,l.kt)("inlineCode",{parentName:"p"},"python3 -m pip install")," is recommended over ",(0,l.kt)("inlineCode",{parentName:"p"},"pip install"))),(0,l.kt)("h2",{id:"train-the-model"},"Train the model"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"The training code in this repo is copied from ",(0,l.kt)("a",{parentName:"p",href:"https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html"},"Pytorch Tutorial"),". However, the dataset part is modified to understand better how Starwhale works.")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-console"},"(pytorch_text) $ mkdir models\n(pytorch_text) $ cd code\n(pytorch_text) $ python train.py --device cpu --save-model-path  ../models/model.i --dictionary ../models/vocab.i --num-epochs 5\n")),(0,l.kt)("p",null,"You will get the logs as below:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-console"},"| epoch   1 |   500/ 7125 batches | accuracy    0.385\n| epoch   1 |  1000/ 7125 batches | accuracy    0.660\n| epoch   1 |  1500/ 7125 batches | accuracy    0.771\n| epoch   1 |  2000/ 7125 batches | accuracy    0.813\n| epoch   1 |  2500/ 7125 batches | accuracy    0.842\n| epoch   1 |  3000/ 7125 batches | accuracy    0.860\n| epoch   1 |  3500/ 7125 batches | accuracy    0.852\n| epoch   1 |  4000/ 7125 batches | accuracy    0.869\n| epoch   1 |  4500/ 7125 batches | accuracy    0.875\n| epoch   1 |  5000/ 7125 batches | accuracy    0.876\n| epoch   1 |  5500/ 7125 batches | accuracy    0.884\n| epoch   1 |  6000/ 7125 batches | accuracy    0.881\n| epoch   1 |  6500/ 7125 batches | accuracy    0.883\n| epoch   1 |  7000/ 7125 batches | accuracy    0.894\n-----------------------------------------------------------\n| end of epoch   1 | time: 28.79s | valid accuracy    0.896\n-----------------------------------------------------------\n| epoch   2 |   500/ 7125 batches | accuracy    0.922\n| epoch   2 |  1000/ 7125 batches | accuracy    0.915\n......\n......\n| epoch   5 |  6000/ 7125 batches | accuracy    0.918\n| epoch   5 |  6500/ 7125 batches | accuracy    0.925\n| epoch   5 |  7000/ 7125 batches | accuracy    0.922\n-----------------------------------------------------------\n| end of epoch   5 | time: 27.34s | valid accuracy    0.900\n-----------------------------------------------------------\nChecking the results of test dataset.\ntest accuracy    0.877\nSaving model to ../models/model.i\nSave vocab to ../models/vocab.i\n")),(0,l.kt)("p",null,"Great! Now you have your model trained and saved. You can see it in the ",(0,l.kt)("inlineCode",{parentName:"p"},"models")," directory."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-console"},"(pytorch_text) $ ls ../models\nmodel.i  vocab.i\n")),(0,l.kt)("h2",{id:"slice-the-test-dataset-using-the-starwhale-protocol"},"Slice the test dataset using the Starwhale protocol"),(0,l.kt)("p",null,"In the training section, we use a dataset called ",(0,l.kt)("a",{parentName:"p",href:"https://paperswithcode.com/dataset/ag-news"},"AG_NEWS"),"."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-console"},"(pytorch_text) $ ls ../data\ntest.csv  train.csv\n")),(0,l.kt)("p",null,"The test part of the dataset is a file called ",(0,l.kt)("inlineCode",{parentName:"p"},"test.csv"),", which contains 7,600 lines of texts and labels."),(0,l.kt)("p",null,"Before version ",(0,l.kt)("inlineCode",{parentName:"p"},"0.2.x"),", Starwhale sliced the dataset into chunks where the batched texts and labels reside. You must tell Starwhale how to yield batches of byte arrays from each dataset file."),(0,l.kt)("p",null,"In this example, we will read texts and labels in batch and convert them into byte arrays."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'def yield_data(path, label=False):\n    data = ag_news.load_ag_data(path)\n    idx = 0\n    data_size = len(data)\n    while True:\n        last_idx = idx\n        idx += 1\n        if idx > data_size:\n            break\n        data_batch = [lbl if label else txt for lbl, txt in\n                      data[last_idx:idx]]\n        join = "#@#@#@#".join(data_batch)\n        yield join.encode()\n\nclass AGNEWSSlicer(BuildExecutor):\n\n    def iter_data_slice(self, path: str):\n        yield from yield_data(path)\n\n    def iter_label_slice(self, path: str):\n        yield from yield_data(path, True)\n\n\n')),(0,l.kt)("p",null,"You need to extend the abstract class ",(0,l.kt)("inlineCode",{parentName:"p"},"BuildExecutor"),", so Starwhale can use it. The ",(0,l.kt)("inlineCode",{parentName:"p"},"path")," argument is a file that matches ",(0,l.kt)("inlineCode",{parentName:"p"},"data_filter")," or ",(0,l.kt)("inlineCode",{parentName:"p"},"label_filter")," in ",(0,l.kt)("inlineCode",{parentName:"p"},"${code_base}/example/text_cls_AG_NEWS/dataset.yaml"),". The filters used in this example are ",(0,l.kt)("inlineCode",{parentName:"p"},"test.csv"),"."),(0,l.kt)("h2",{id:"implement-the-inference-method-and-evaluation-metrics-computing-method"},"Implement the inference method and evaluation metrics computing method"),(0,l.kt)("p",null,"The inference method is called ",(0,l.kt)("inlineCode",{parentName:"p"},"ppl,")," and the evaluation metrics computing method is called ",(0,l.kt)("inlineCode",{parentName:"p"},"cmp"),".\nHere is the code snap from ",(0,l.kt)("inlineCode",{parentName:"p"},"ppl.py"),", which implements both methods. You need to extend the abstract class ",(0,l.kt)("inlineCode",{parentName:"p"},"PipelineHandler")," so you can receive the byte arrays, which you transformed in the last step."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'class TextClassificationHandler(PipelineHandler):\n\n    def __init__(self, device="cpu") -> None:\n        super().__init__(merge_label=True, ignore_error=True)\n        self.device = torch.device(device)\n\n    @torch.no_grad()\n    def ppl(self, data, **kw):\n        _model, vocab, tokenizer = self._load_model(self.device)\n        texts = data.decode().split(\'#@#@#@#\')\n        return list(map(lambda text: predict.predict(text, _model, vocab, tokenizer, 2), texts)), None\n\n    def handle_label(self, label, **kw):\n        labels = label.decode().split(\'#@#@#@#\')\n        return[int(label) for label in labels]\n\n    @multi_classification(\n        confusion_matrix_normalize="all",\n        show_hamming_loss=True,\n        show_cohen_kappa_score=True,\n        show_roc_auc=False,\n        all_labels=[i for i in range(1, 5)],\n    )\n    def cmp(self, _data_loader):\n        _result, _label = [], []\n        for _data in _data_loader:\n            print(_data)\n            _label.extend([int(l) for l in _data["label"]])\n            _result.extend([int(r) for r in _data["result"]])\n        return _label, _result\n\n    def _load_model(self, device):\n        model_path = _ROOT_DIR + "/models/model.i"\n        _model = model.TextClassificationModel(1308713, 32, 4).to(device)\n        _model.load_state_dict(torch.load(model_path))\n        _model.eval()\n        vocab_path = _ROOT_DIR + "/models/vocab.i"\n        dictionary = torch.load(vocab_path)\n        tokenizer = get_tokenizer("basic_english")\n        return _model, dictionary, tokenizer\n')),(0,l.kt)("h3",{id:"implement-ppl"},"Implement ppl"),(0,l.kt)("p",null,"Starwhale will feed the byte arrays of one batch to the ",(0,l.kt)("inlineCode",{parentName:"p"},"ppl")," method and put the output of ",(0,l.kt)("inlineCode",{parentName:"p"},"ppl")," into an ",(0,l.kt)("inlineCode",{parentName:"p"},"inference_result")," dict, which looks like:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-json"},'{"result":[{resultObj1},{resultObj2}],"label":[{labelObj1},{labelObj2}]}\n')),(0,l.kt)("p",null,"Starwhale will automatically add the result of ",(0,l.kt)("inlineCode",{parentName:"p"},"ppl")," to ",(0,l.kt)("inlineCode",{parentName:"p"},"inference_result.result")," and the result of ",(0,l.kt)("inlineCode",{parentName:"p"},"handle_label")," to ",(0,l.kt)("inlineCode",{parentName:"p"},"inference_result.label"),"."),(0,l.kt)("p",null,"The ",(0,l.kt)("inlineCode",{parentName:"p"},"inference_result")," is used in the argument of ",(0,l.kt)("inlineCode",{parentName:"p"},"cmp")," named ",(0,l.kt)("inlineCode",{parentName:"p"},"_data_loader"),"."),(0,l.kt)("h3",{id:"implement-cmp"},"Implement cmp"),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"_data_loader")," is an iterator for ",(0,l.kt)("inlineCode",{parentName:"p"},"result")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"label"),". For a multiple classification problem, it is pretty easy to implement the ",(0,l.kt)("inlineCode",{parentName:"p"},"cmp")," method by annotating your ",(0,l.kt)("inlineCode",{parentName:"p"},"cmp")," method with the ",(0,l.kt)("inlineCode",{parentName:"p"},"multi_classification")," annotation and coping the lines inside it. Because AG_NEWS has only 4 labels, ",(0,l.kt)("inlineCode",{parentName:"p"},"all_labels")," is set to ",(0,l.kt)("inlineCode",{parentName:"p"},"[i for i in range(1, 5)]")),(0,l.kt)("p",null,"If you need to show ",(0,l.kt)("inlineCode",{parentName:"p"},"roc")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"auc"),", you will also need to supply ",(0,l.kt)("inlineCode",{parentName:"p"},"_pr")," in your ",(0,l.kt)("inlineCode",{parentName:"p"},"ppl")," method."),(0,l.kt)("p",null,"By now, we have finished all the coding parts. Then let's begin the command line part."),(0,l.kt)("h2",{id:"build-runtime-model-and-dataset"},"Build Runtime, Model, and Dataset"),(0,l.kt)("h3",{id:"build-runtime"},"Build Runtime"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-console"},"(pytorch_text) $ cd ..\n(pytorch_text) $ swcli runtime build .\n\ud83d\udea7 start to build runtime bundle...\n\ud83d\udc77 uri:local/project/self/runtime/pytorch_text\n\ud83d\udc26 runtime will ignore pypi editable package\n\ud83c\udd95 version mnqtgyjrhezd\n\ud83d\udcc1 workdir: ~/.cache/starwhale/self/workdir/runtime/pytorch_text/mn/mnqtgyjrhezdmodbmu4tezrsgvvdgmq\n\ud83d\udcab python3.9.5@venv, os(Linux), include-editable(False), try to export environment...\n\ud83c\udf08 runtime docker image: ghcr.io/star-whale/starwhale:0.2.0-alpha.  \ud83c\udf08\n\ud83e\udd8b .swrt bundle:~/.cache/starwhale/self/runtime/pytorch_text/mn/mnqtgyjrhezdmodbmu4tezrsgvvdgmq.swrt\n")),(0,l.kt)("h3",{id:"build-dataset"},"Build Dataset"),(0,l.kt)("h4",{id:"write-the-yaml-file"},"Write the yaml file"),(0,l.kt)("p",null,"Here is some descriptive information needed for Starwhale to build a Starwhale Dataset(SWDS). A yaml file describes the information as below:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},'name: AG_NEWS\n\ndata_dir: data\ndata_filter: "test.csv"\nlabel_filter: "test.csv"\n\nprocess: code.data_slicer:AGNEWSSlicer\npip_req: requirements.txt\n\ndesc: AG_NEWS data and label test dataset\ntag:\n - bin\n\nattr:\n  alignment_size: 4k\n  volume_size: 2M\n')),(0,l.kt)("p",null,"Most of the fields are self-explained. The ",(0,l.kt)("inlineCode",{parentName:"p"},"process")," descriptor is the entry point of the data split method. The ",(0,l.kt)("inlineCode",{parentName:"p"},"data_filter")," is for searching files containing data named like ",(0,l.kt)("inlineCode",{parentName:"p"},"test.csv")," recursively under ",(0,l.kt)("inlineCode",{parentName:"p"},"data_dir"),". Then Starwhale will use the files found as the input for ",(0,l.kt)("inlineCode",{parentName:"p"},"process"),"."),(0,l.kt)("p",null,"After creating the yaml file under ",(0,l.kt)("inlineCode",{parentName:"p"},"${code_base}/example/text_cls_AG_NEWS/"),", we are ready."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-console"},"$ swcli dataset build .\n\ud83d\udea7 start to build dataset bundle...\n\ud83d\udc77 uri:local/project/self/dataset/ag_news\n\ud83c\udd95 version gaygeyrsmi2w\n\ud83d\udcc1 swds workdir: ~/.cache/starwhale/self/dataset/ag_news/ga/gaygeyrsmi2wcmrsmuydgy3enrzdm5i.swds\n\ud83d\udc4d try to copy source code files...\n\ud83d\udc7b import code.data_slicer:AGNEWSSlicer@~/code/starwhale/example/text_cls_AG_NEWS to make swds...\ncleanup done.\nfinish gen swds @ ~/.cache/starwhale/self/dataset/ag_news/ga/gaygeyrsmi2wcmrsmuydgy3enrzdm5i.swds/data\n\ud83e\udd16 calculate signature...\n\ud83c\udf3a congratulation! you can run  swcli dataset info ag_news/version/gaygeyrsmi2wcmrsmuydgy3enrzdm5i\n  8 out of 8 steps finished \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 100% 0:00:00 0:00:00\n")),(0,l.kt)("p",null,"There is one more step left."),(0,l.kt)("h3",{id:"build-model"},"Build Model"),(0,l.kt)("p",null,"Here is some descriptive information for Starwhale to build a Starwhale Model Package(SWMP). A yaml file describes the information as below:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"version: 1.0\nname: text_cls\n\nmodel:\n  - models/model.i\n  - models/vocab.i\n\nconfig:\n  - config/hyperparam.json\n\nrun:\n  ppl: code.ppl:TextClassificationHandler\n  pip_req: requirements.txt\n  exclude_pkg_data:\n    - venv\n    - .git\n    - .history\n    - .vscode\n\ndesc: TextClassification by PyTorch\n\ntag:\n  - TextClassification\n")),(0,l.kt)("p",null,"Most of the fields are self-explained. The ",(0,l.kt)("inlineCode",{parentName:"p"},"ppl")," descriptor is the entry point of the inference and cmp method.\nAfter creating the yaml file under ",(0,l.kt)("inlineCode",{parentName:"p"},"${code_base}/example/text_cls_AG_NEWS/"),", we are ready."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-console"},"(pytorch_text) $ swcli model build .\n\ud83d\udea7 start to build model bundle...\n\ud83d\udc77 uri:local/project/self/model/text_cls\n\ud83c\udd95 version mq2tmmlfgmzd\n\ud83d\udcc1 workdir: ~/.cache/starwhale/self/workdir/model/text_cls/mq/mq2tmmlfgmzdqztfgbqtmntfg53dk4a\n\ud83d\udc4d try to copy source code files...\n\ud83e\udd8b .swmp bundle:~/.cache/starwhale/self/model/text_cls/mq/mq2tmmlfgmzdqztfgbqtmntfg53dk4a.swmp\n")),(0,l.kt)("p",null,"Here we are. We have finished all the complex parts."),(0,l.kt)("h2",{id:"run-the-evaluation-job-and-see-the-metrics"},"Run the evaluation job and see the metrics"),(0,l.kt)("p",null,"We have two ways to evaluate our models:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Evaluate model on a standalone instance"),(0,l.kt)("li",{parentName:"ul"},"Evaluate model on a cloud instance")),(0,l.kt)("h3",{id:"evaluate-the-model-on-your-local-standalone-instance"},"Evaluate the model on your local standalone instance"),(0,l.kt)("h4",{id:"create-a-job"},"Create a job"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-console"},"$ swcli -vvv job create self --model text_cls/version/latest --dataset ag_news/version/latest --runtime pytorch_text/version/latest --docker-verbose\n2022-06-09 19:09:45.085 | 0:00:01.898337 | DEBUG    | starwhale.utils.debug:init_logger:42 - verbosity: 3, log level: DEBUG\n\u280b eval run in local... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501   0% -:--:-- 0:00:002022-06-09 19:09:45.090 | 0:00:01.903792 | INFO     | starwhale.core.job.executor:_gen_version:113 - [step:version]create eval job version...\n2022-06-09 19:09:45.093 | 0:00:01.906845 | INFO     | starwhale.core.job.executor:_gen_version:118 - [step:version]eval job version is mfrdcyrxhftdgzlgmqytsmbsnvztiyq\n2022-06-09 19:09:45.093 | 0:00:01.907084 | INFO     | starwhale.core.job.executor:_prepare_workdir:129 - [step:prepare]create eval workdir...\n2022-06-09 19:09:45.095 | 0:00:01.908800 | INFO     | starwhale.core.job.executor:_prepare_workdir:151 - [step:prepare]eval workdir: ~/.cache/starwhale/self/job/mf/mfrdcyrxhftdgzlgmqytsmbsnvztiyq\n\ud83d\ude39 ~/.cache/starwhale/self/workdir/model/text_cls/gz/gzstmmztmyytmztfgbqtmntfn43gqoi existed, skip extract model bundle\n\ud83d\ude39 ~/.cache/starwhale/self/workdir/runtime/pytorch_text/hb/hbtdqnztmy2dky3cmqzdazjymn4dqzi existed, skip extract model bundle\n\ud83d\ude39 local_fuse.json existed, skip render\n\ud83d\udd0d ~/.cache/starwhale/self/dataset/ag_news/me/me3tkzdgga4tgmrsmuydgy3ehfshu6i.swds/local_fuse.json\n\u280b eval run in local... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501   0% -:--:-- 0:00:002022-06-09 19:09:45.106 | 0:00:01.919282 | DEBUG    | starwhale.core.job.executor:_gen_swds_fuse_json:166 - [gen fuse input.json]~/.cache/starwhale/self/dataset/ag_news/me/me3tkzdgga4tgmrsmuydgy3ehfshu6i.swds/local_fuse.json\n2022-06-09 19:09:45.106 | 0:00:01.919864 | INFO     | starwhale.core.job.executor:_do_run_cmd:217 - [run ppl] docker run command output...\n\n\ud83d\udc18 ppl docker cmd\ndocker run --net=host --rm --name mfrdcyrxhftdgzlgmqytsmbsnvztiyq-ppl -v ~/.cache/starwhale/self/job/mf/mfrdcyrxhftdgzlgmqytsmbsnvztiyq/ppl:/opt/starwhale -v ~/.cache/starwhale/self/workdir/model/text_cls/gz/gzstmmztmyytmztfgbqtmntfn43gqoi/src:/opt/starwhale/swmp/src -v ~/.cache/starwhale/self/workdir/model/text_cls/gz/gzstmmztmyytmztfgbqtmntfn43gqoi/model.yaml:/opt/starwhale/swmp/model.yaml -v ~/.cache/starwhale/self/workdir/runtime/pytorch_text/hb/hbtdqnztmy2dky3cmqzdazjymn4dqzi/dep:/opt/starwhale/swmp/dep -v ~/.cache/starwhale/self/workdir/runtime/pytorch_text/hb/hbtdqnztmy2dky3cmqzdazjymn4dqzi/_manifest.yaml:/opt/starwhale/swmp/_manifest.yaml -v ~/.cache/starwhale/self/dataset:/opt/starwhale/dataset -v ~/.cache/starwhale-pip:/root/.cache/pip -e DEBUG=1 ghcr.io/star-whale/starwhale:latest ppl\n\n\ud83d\udc1f eval run:ppl dir @ ~/.cache/starwhale/self/job/mf/mfrdcyrxhftdgzlgmqytsmbsnvztiyq/ppl\n\u280b eval run in local... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501   0% -:--:-- 0:00:002022-06-09 19:09:45.116 | 0:00:01.929534 | DEBUG    | starwhale.utils.process:log_check_call:20 - cmd: 'docker pull ghcr.io/star-whale/starwhale:latest'\n......logs omitted......\n......logs omitted......\n\u283c run ppl... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2578\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501  26% 0:00:01 0:08:252022-06-09 19:18:11.233 | 0:08:28.046963 | DEBUG    | starwhale.utils.process:log_check_call:25 - 2022-06-09 11:18:11.232 | 0:04:30.197662 | INFO     | starwhale.api._impl.model:_starwhale_internal_run_ppl:268 - [115] data handle -> success\n2022-06-09 19:18:11.234 | 0:08:28.047501 | DEBUG    | starwhale.utils.process:log_check_call:25 - 2022-06-09 11:18:11.233 | 0:04:30.198691 | INFO     | starwhale.api._impl.model:_starwhale_internal_run_ppl:229 - [116]data-label loaded, data size:14.73KB, label size:505.00B ,batch:64\n\u2826 run ppl... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2578\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501  26% 0:00:01 0:08:262022-06-09 19:18:12.375 | 0:08:29.188626 | DEBUG    | starwhale.utils.process:log_check_call:25 - 2022-06-09 11:18:12.374 | 0:04:31.339085 | INFO     | starwhale.api._impl.model:_starwhale_internal_run_ppl:268 - [116] data handle -> success\n2022-06-09 19:18:12.377 | 0:08:29.190733 | DEBUG    | starwhale.utils.process:log_check_call:25 - 2022-06-09 11:18:12.377 | 0:04:31.341953 | INFO     | starwhale.api._impl.model:_starwhale_internal_run_ppl:229 - [117]data-label loaded, data size:15.06KB, label size:505.00B ,batch:64\n\u280f run ppl... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2578\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501  26% 0:00:01 0:08:272022-06-09 19:18:13.661 | 0:08:30.474491 | DEBUG    | starwhale.utils.process:log_check_call:25 - 2022-06-09 11:18:13.660 | 0:04:32.625002 | INFO     | starwhale.api._impl.model:_starwhale_internal_run_ppl:268 - [117] data handle -> success\n2022-06-09 19:18:13.662 | 0:08:30.475502 | DEBUG    | starwhale.utils.process:log_check_call:25 - 2022-06-09 11:18:13.661 | 0:04:32.626688 | INFO     | starwhale.api._impl.model:_wrapper:209 - finish.\n2022-06-09 19:18:13.663 | 0:08:30.477178 | DEBUG    | starwhale.utils.process:log_check_call:25 - 2022-06-09 11:18:13.663 | 0:04:32.628394 | Level 20 | rich.console:_check_buffer:1951 - \ud83d\udc4f finish run ppl: PipelineHandler status@/opt/starwhale/status, log@/opt/starwhale/log, result@/opt/starwhale/result\n2022-06-09 19:18:13.853 | 0:08:30.666685 | DEBUG    | starwhale.utils.process:log_check_call:25 - \ud83d\udc4f finish run ppl: PipelineHandler status@/opt/starwhale/status, log@/opt/starwhale/log, result@/opt/starwhale/result\n2022-06-09 19:18:14.033 | 0:08:30.846635 | DEBUG    | starwhale.utils.process:log_check_call:25 -\n2022-06-09 19:18:14.034 | 0:08:30.848083 | INFO     | starwhale.core.job.executor:_do_run_cmd:217 - [run cmp] docker run command output...\n\n\ud83d\udc18 cmp docker cmd\ndocker run --net=host --rm --name mfrdcyrxhftdgzlgmqytsmbsnvztiyq-cmp -v ~/.cache/starwhale/self/job/mf/mfrdcyrxhftdgzlgmqytsmbsnvztiyq/cmp:/opt/starwhale -v ~/.cache/starwhale/self/workdir/model/text_cls/gz/gzstmmztmyytmztfgbqtmntfn43gqoi/src:/opt/starwhale/swmp/src -v ~/.cache/starwhale/self/workdir/model/text_cls/gz/gzstmmztmyytmztfgbqtmntfn43gqoi/model.yaml:/opt/starwhale/swmp/model.yaml -v ~/.cache/starwhale/self/workdir/runtime/pytorch_text/hb/hbtdqnztmy2dky3cmqzdazjymn4dqzi/dep:/opt/starwhale/swmp/dep -v ~/.cache/starwhale/self/workdir/runtime/pytorch_text/hb/hbtdqnztmy2dky3cmqzdazjymn4dqzi/_manifest.yaml:/opt/starwhale/swmp/_manifest.yaml -v ~/.cache/starwhale/self/job/mf/mfrdcyrxhftdgzlgmqytsmbsnvztiyq/ppl/result:/opt/starwhale/ppl_result -v ~/.cache/starwhale-pip:/root/.cache/pip -e DEBUG=1 ghcr.io/star-whale/starwhale:latest cmp\n\n\ud83d\udc1f eval run:cmp dir @ ~/.cache/starwhale/self/job/mf/mfrdcyrxhftdgzlgmqytsmbsnvztiyq/cmp\n\u2819 run cmp... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501  63% -:--:-- 0:08:282022-06-09 19:18:14.043 | 0:08:30.856355 | DEBUG    | starwhale.utils.process:log_check_call:20 - cmd: 'docker pull ghcr.io/star-whale/starwhale:latest'\n......logs omitted......\n......logs omitted......\n2022-06-09 19:18:23.015 | 0:08:39.828563 | DEBUG    | starwhale.utils.process:log_check_call:25 - 2022-06-09 11:18:23.013 | 0:00:01.444597 | INFO     | starwhale.api._impl.model:_wrapper:209 - finish.\n\u283c run cmp... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u257a\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501  63% -:--:-- 0:08:372022-06-09 19:18:23.159 | 0:08:39.972502 | DEBUG    | starwhale.utils.process:log_check_call:25 - 2022-06-09 11:18:23.014 | 0:00:01.445667 | Level 20 | rich.console:_check_buffer:1951 - \ud83d\udc4f finish run cmp: PipelineHandler status@/opt/starwhale/status, log@/opt/starwhale/log, result@/opt/starwhale/result\n2022-06-09 19:18:23.159 | 0:08:39.972795 | DEBUG    | starwhale.utils.process:log_check_call:25 - {'index': 116, 'result': [2, 3, 1, 4, 2, 4, 3, 3, 2, 2, 2, 2, 1, 1, 3, 4, 1, 3, 2, 1, 3, 2, 1, 2, 3, 3, 3, 3, 3, 4, 2, 3, 4, 2, 1, 1, 1, 1, 3, 3, 3, 3, 3, 1, 3, 1, 4, 2, 4, 1, 1, 1, 1, 1, 4, 1, 3, 1, 1, 1, 3, 4, 2, 2], 'pr': None, 'batch': 64, 'label': [2, 3, 4, 4, 2, 4, 3, 3, 2, 2, 2, 2, 1, 4, 3, 4, 4, 3, 2, 1, 3, 2, 3, 2, 3, 3, 3, 3, 3, 4, 2, 3, 4, 2, 1, 1, 1, 4, 3, 3, 3, 3, 4, 1, 3, 4, 3, 1, 4, 1, 1, 2, 1, 1, 4, 2, 3, 4, 1, 1, 2, 4, 2, 2]}\n2022-06-09 19:18:23.314 | 0:08:40.128161 | DEBUG    | starwhale.utils.process:log_check_call:25 - {'index': 117, 'result': [3, 2, 1, 4, 1, 4, 4, 1, 1, 4, 1, 4, 2, 3, 1, 3, 4, 1, 2, 3, 3, 1, 1, 3, 1, 4, 4, 1, 1, 2, 4, 1, 4, 4, 3, 3, 3, 2, 1, 4, 2, 1, 3, 2, 2, 1, 1, 3, 1, 3, 1, 4, 1, 4, 3, 1, 1, 1, 4, 3, 3, 3, 1, 2], 'pr': None, 'batch': 64, 'label': [3, 2, 1, 4, 3, 4, 4, 1, 3, 4, 4, 4, 2, 3, 1, 3, 4, 1, 2, 3, 3, 1, 1, 3, 1, 4, 4, 3, 1, 2, 4, 1, 4, 4, 4, 3, 3, 2, 1, 4, 2, 1, 3, 2, 2, 1, 1, 3, 1, 3, 1, 1, 1, 4, 4, 3, 1, 1, 4, 3, 3, 3, 2, 2]}\n  7 out of 7 steps finished \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 100% 0:00:00 0:08:38\n\ud83d\udc4f success to create job(project id: self)\n")),(0,l.kt)("h4",{id:"see-the-metrics"},"See the metrics"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-console"},"(pytorch_text) $ swcli job info mfrdcyrxhftdgzlgmqytsmbsnvztiyq\n{\n    'created_at': '2022-06-09 19:09:45 CST',\n    'datasets': [\n        'local/project/self/dataset/ag_news/version/latest'\n    ],\n    'desc': None,\n    'finished_at': '2022-06-09 19:18:23 CST',\n    'model': 'local/project/self/model/text_cls/version/latest',\n    'name': None,\n    'phase': 'all',\n    'runtime': 'local/project/self/runtime/pytorch_text/version/latest',\n    'status': 'success',\n    'version': 'mfrdcyrxhftdgzlgmqytsmbsnvztiyq'\n}\n\n\ud83c\udf35 ppl: ~/.cache/starwhale/self/job/mf/mfrdcyrxhftdgzlgmqytsmbsnvztiyq/ppl\n\ud83d\udc2b cmp: ~/.cache/starwhale/self/job/mf/mfrdcyrxhftdgzlgmqytsmbsnvztiyq/cmp\n\nSummary\n\u251c\u2500\u2500 accuracy: 0.8059                                                                                   Label   Precision   Recall   F1-score   Support\n\u251c\u2500\u2500 macro avg                                                                                         \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2502   \u251c\u2500\u2500 precision: 0.8427                                                                              1       0.6313      0.9487   0.7581     3780.0000\n\u2502   \u251c\u2500\u2500 recall: 0.8059                                                                                 2       0.9610      0.8110   0.8797     3768.0000\n\u2502   \u251c\u2500\u2500 f1-score: 0.8098                                                                               3       0.8554      0.7834   0.8178     3776.0000\n\u2502   \u2514\u2500\u2500 support: 15104.0000                                                                            4       0.9232      0.6804   0.7834     3780.0000\n\u251c\u2500\u2500 weighted avg\n\u2502   \u251c\u2500\u2500 precision: 0.8426\n\u2502   \u251c\u2500\u2500 recall: 0.8059\n\u2502   \u251c\u2500\u2500 f1-score: 0.8097\n\u2502   \u2514\u2500\u2500 support: 15104.0000\n\u251c\u2500\u2500 hamming_loss: 0.1941\n\u2514\u2500\u2500 cohen_kappa_score: 0.7412\n\n  Label   TP      TN     FP     FN                                                                                                            1        2        3        4\n \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                                                                    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  1       9230    2094   194    3586                                                                                                      1   0.2374   0.0048   0.0061   0.0020\n  2       11212   124    712    3056                                                                                                      2   0.0446   0.2023   0.0021   0.0004\n  3       10828   500    818    2958                                                                                                      3   0.0413   0.0011   0.1958   0.0118\n  4       11110   214    1208   2572                                                                                                      4   0.0527   0.0024   0.0249   0.1703\n")),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"\ud83d\udca1 Docker is required to run as a demon service on the machine")),(0,l.kt)("p",null,"Congratulations, we have finished the whole example! From now on, we can update the training method, get a new model, build a new SWMP, and evaluate our model from time to time."),(0,l.kt)("h3",{id:"evaluate-model-on-a-cloud-instance"},"Evaluate model on a cloud instance"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Log in to one cloud instance"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-console"},"(pytorch_text) $ swcli instance login http://console.pre.intra.starwhale.ai --username starwhale --password abcd1234 --alias pre-k8s\n\u200d\ud83c\udf73 login http://console.pre.intra.starwhale.ai successfully!\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Copy the model we built before to the cloud instance"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-console"},"(pytorch_text) $ swcli model copy text_cls/version/gzstmmztmyyt cloud://pre-k8s/project/1\n\ud83d\udea7 start to copy local/project/self/model/text_cls/version/gzstmmztmyyt -> http://console.pre.intra.starwhale.ai/project/1...\n  \ud83c\udfb3 upload gzstmmztmyytmztfgbqtmntfn43gqoi.swmp \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 100% 0:00:16 196.7 MB 10.6 MB/s\n\ud83d\udc4f copy done.\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Copy the dataset we built before to the cloud instance"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-console"},"(pytorch_text) $ swcli dataset copy ag_news/version/me3tkzdgga4t cloud://pre-k8s/project/1\n    \ud83d\udea7 start to copy local/project/self/dataset/ag_news/version/me3tkzdgga4t -> http://console.pre.intra.starwhale.ai/project/1...\n    \u2b06 _manifest.yaml         \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 100% 0:00:00 1.2 kB   ?\n\u2b06 data_ubyte_0.swds_bin  \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 100% 0:00:00 2.0 MB   ?\n\u2b06 index.jsonl            \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 100% 0:00:00 20.9 kB  ?\n\u2b06 label_ubyte_0.swds_bin \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 100% 0:00:00 479.6 kB ?\n\u2b06 archive.swds_meta      \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 100% 0:00:00 20.5 kB  ?\n\ud83d\udc4f copy done\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Copy the runtime we built before to the cloud instance"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-console"},"(pytorch_text) $ swcli runtime copy pytorch_text/version/hbtdqnztmy2d cloud://pre-k8s/project/1\n\ud83d\udea7 start to copy local/project/self/runtime/pytorch_text/version/hbtdqnztmy2d -> http://console.pre.intra.starwhale.ai/project/1...\n  \ud83c\udfb3 upload hbtdqnztmy2dky3cmqzdazjymn4dqzi.swrt \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 100% 0:00:00 20.5 kB ?\n\ud83d\udc4f copy done.\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Go to the console and create one job"))),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"img.png",src:a(3210).Z,width:"2560",height:"1289"})))}p.isMDXComponent=!0},3210:function(e,t,a){t.Z=a.p+"assets/images/create_job_ag_news-467923671b4523073edceeacb47d569a.png"}}]);