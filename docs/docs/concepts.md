# Overview

This document explains the main concepts in Starwhale.


```
            Instance
               |
            Project
               |
   +-------+---+---+------+
   |       |       |      |
 Model  Dataset Runtime  Job
   |       |       |      |
Version Version Verison  Step
                          |
                         Task
```

# Instance

Each installation of Starwhale is called an instance. Generally, Starwhale has 3 types of instances:
- Standalone instance
- On-Premises instance
- Hosted instance

The standalone instance is the simplest form. It requires only the Starwhale client (swcli). All data and metadata are stored locally on the client machine. All jobs and tasks are executed on the client machine as well. It is similar to git, which requires only a set of executable binaries.

The on-premises instance and hosted instance are both called cloud instances. We can call the on-premises instance "private cloud instance" and the hosted instance "public cloud instance". They both have a controller component and some optional agent components installed on one or more servers. The main difference is that on-premises instances are maintained by operation teams in different organizations and hosted instances are maintained by the Starwhale team on the public cloud.

Starwhale tries to keep concepts consistent across different types of instances. In this way, people can easily exchange data and migrate between different instances.

# Project

Project is the basic unit for organizing different resources like models, datasets, etc. 
Users may use projects for different purposes. For example, a project can be created for a data scientist team, for a product line, or just for a specific model. Users usually work on one or more projects in their daily lives.
Every user in cloud instances has their personal project by default. Standalone instances do not have such a thing because they are mainly intended for single-user usage.

# Model

Starwhale Model is the standard model format used in model delivery. 

A Starwhale Model is a directory containing arbitrary files. It contains the model file generated by ML frameworks, the code file to run the model, the metadata file defined by Starwhale, and many other files.

A Starwhale Model can contain any information required to run the model, such as source codes, different model formats, etc. It can be stripped of redundant information to get a slight package. The main purpose of a stripped Starwhale Model Package is for delivery. Users may not want to show python inference code to the production team for security reasons, or simply need a minimum deployable package on the edge.

# Runtime

Starwhale Runtime describes software dependencies to "run" a model. It includes python libraries, native libraries, native binaries, etc.

Stable software dependencies are essential for running a model. One reason is that installing dependencies is paining for most scientists. People spend days fighting with obscure error messages and finally become frustrated. Another reason is that deep learning natural networks are very sensitive, a minuscule error in input may lead to a very big difference in output. Even different versions of a dependent library may impact model performance severely. Thus, it is important to define the software runtime environment precisely.

Conda, Pip, and docker images are all solutions to define the software runtime environment. Starwhale Runtime supports all of them. Users can choose anyone they are familiar with.
Starwhale provides the ability to synchronize runtimes on different machines and to switch between runtimes. Build once, use anywhere.

# Dataset

Starwhale organizes data into datasets. 

Different data usually have different storage formats and can be stored on different storage systems. Besides the original data, labels play a very important role in ML. Users usually label data from multiple perspectives and use them in different models later.

Starwhale dataset provides a unified description of how the data and labels are stored and organized. In this way, users can process data and labels easily.

Starwhale Dataset is just a collection of arbitrary data. It is up to the user how to define a dataset. 

# Version

Starwhale manages the history of Model, Dataset, and Runtime. Every update appends a new version to the history.

Versions are identified by version id which is generated automatically by Starwhale and ordered by creation time.

Starwhale uses a linear history model. There is neither branch nor cycle in history. History can not be rollback. When a version is to be reverted, Starwhale copies the version and appends it to the end of the history. However, versions in the history can be manually removed and recovered.

# Job, Step, and Task

A job is a set of programs to do specific work. A job consists of one or more steps, and each step consists of one or more tasks. Steps represent different stages of the work. They usually run with different codes. Tasks mean different parts of a step. Tasks in the same step always share the same program but run with different data input.

Starwhale uses jobs to execute actions like model training, evaluation, and serving.
