---
title: Model CLI
---

## Usage

```bash
swcli model [OPTIONS] COMMAND [ARGS]...
```

## Summary

- Commands for model lifecycle management.
- For standalone instances, the `model` command uses the local disk to create, build, and store **Starwhale Model**.
- For cloud instances, the `model` command manages remote models through HTTP API.
- **Model URI** in format: `[<Project URI>/model]<model name>[/version/<version id>]`.

## All Sub-Commands

  | Command |Standalone|Cloud|
  |-------|----------|-----|
  | build   |✅|❌|
  | cmp     |✅|❌|
  | ppl     |✅|❌|
  | eval    |✅|❌|
  | remove  |✅|✅|
  | recover |✅|✅|
  | list    |✅|✅|
  | history |✅|✅|
  | info    |✅|✅|
  | tag     |✅|❌|
  | diff    |✅|❌|
  | copy    |✅|✅|

## Build a model

```bash
swcli model build [OPTIONS] WORKDIR
```

- This command builds a model within the specified working directory. The working dir must contain a `model.yaml`.
- Options:

    |Option|Alias Option|Required|Type|Default|Description|
    |------|--------|-------|-----------|-----|-----------|
    |`--project`|`-p`|❌|String|Selected project|Project URI|
    |`--runtime-yaml`|`-f`|❌|String|model.yaml|Model yaml filename, default is ${WORKDIR}/model.yaml|

- Example:

    ```bash
    ❯ swcli model build .
    🚧 start to build model bundle...
    👷 uri:local/project/self/model/mnist
    🆕 version gbstgnlgheyd
    📁 workdir: /home/liutianwei/.cache/starwhale/self/workdir/model/mnist/gb/gbstgnlgheydqnrtmftdgyjzpe4tezy
    👍 try to copy source code files...
    🦋 .swmp bundle:/home/liutianwei/.cache/starwhale/self/model/mnist/gb/gbstgnlgheydqnrtmftdgyjzpe4tezy.swmp
    6 out of 6 steps finished ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 0:00:00
    ```

## Run model ppl

```bash
swcli model ppl [OPTIONS] TARGET
```

- This command will run ppl defined in the `run.ppl` field of `model.yaml`. When you write a subclass of `starwhale.api.model.PipelineHandler`, the `ppl` class method is required, and it will be invoked by the `ppl` command.
- The `TARGET` argument is required. `Model URI` or the model working dir path is ok for the `TARGET` argument. In the Starwhale agent docker environment, only the working dir path is supported.
- The Starwhale dataset is a precondition for running the `ppl` command. It would be best if you ran `swcli dataset render-fuse` to render `input.json` for the input of `ppl` command.
- Another precondition is the Starwhale runtime. The `ppl` command must run in the activated runtime environment.
- This command helps the developer debug ppl processes. The more human-friendly command to evaluate a model is `swcli job create` or `swcli model eval`.
- Options:

    |Option|Alias Option|Required|Type|Default|Description|
    |------|--------|-------|-----------|-----|-----------|
    |`--model-yaml`|`-f`|❌|String|model.yaml|Model yaml filename, default is ${MODEL_DIR}/model.yaml|
    |`--status-dir`|os env `SW_TASK_STATUS_DIR`|❌|String|/tmp/starwhale/ppl/status|ppl status dir|
    |`--log-dir`|os env `SW_TASK_LOG_DIR`|❌|String|/tmp/starwhale/ppl/log|ppl log dir|
    |`--result-dir`|os env `SW_TASK_RESULT_DIR`|❌|String|/tmp/starwhale/ppl/result|ppl result dir|
    |`--input-config`|os env `SW_TASK_INPUT_CONFIG`|❌|String|/tmp/starwhale/ppl/config/input.json|dataset input.json path or Dataset URI, which was generated by `swcli dataset render-fuse` command|

- Example:

    ```bash
    ❯ swcli model ppl . --input-config mnist/version/latest
    🏌 try to eval ppl @  ....
    try to import mnist.ppl:MNISTInference@....
    🗣  swcli python prefix:/usr, runtime env python prefix:/home/liutianwei/code/starwhale/example/mnist/venv, swcli will inject sys.path
    load mnist model, start to inference...
    👏 finish run ppl: PipelineHandler status@/tmp/starwhale/status, log@/tmp/starwhale/log, result@/tmp/starwhale/result
    ```

## Run model comparison

```bash
swcli model cmp [OPTIONS] TARGET
```

- This command will run a model comparison, defined in the `run.ppl` field of `model.yaml`. When you write a subclass of `starwhale.api.model.PipelineHandler`, the `cmp` class method is required and will be invoked by the `cmp` command.
- Compare inference output with labels, then generate result jsonline file.
- `TARGET` argument is required. The `Model URI` or model working dir path is ok for the `TARGET` argument. In the Starwhale agent docker environment, only the working dir path is supported.
- The result of `ppl` command is a precondition for running the `cmp` command. It would be best if you ran `swcli model ppl` to generate ppl inference output, then write an `input.json` to describe the path of results.
- Another precondition is the Starwhale runtime. The `ppl` command must run in the activated runtime environment.
- This command helps the developer debug the comparison process. The more human-friendly command to evaluate a model is `swcli job create` or `swcli model eval`.
- Options:

    |Option|Alias Option|Required|Type|Default|Description|
    |------|--------|-------|-----------|-----|-----------|
    |`--model-yaml`|`-f`|❌|String|model.yaml|Model yaml filename, default is ${MODEL_DIR}/model.yaml|
    |`--status-dir`|os env `SW_TASK_STATUS_DIR`|❌|String|/tmp/starwhale/cmp/status|cmp status dir|
    |`--log-dir`|os env `SW_TASK_LOG_DIR`|❌|String|/tmp/starwhale/cmp/log|cmp log dir|
    |`--result-dir`|os env `SW_TASK_RESULT_DIR`|❌|String|/tmp/starwhale/cmp/result|cmp result dir|
    |`--input-config`|os env `SW_TASK_INPUT_CONFIG`|❌|String|/tmp/starwhale/cmp/config/input.json|cmp input.json path|

- Example:

   ```bash
   ❯ swcli model cmp . --input-config test/ppl_output_fuse_smoke.json
    🏌 try to eval cmp @  ....
    try to import mnist.ppl:MNISTInference@....
    load mnist model, start to inference...
    👏 finish run cmp: PipelineHandler status@/tmp/starwhale/cmp/status, log@/tmp/starwhale/cmp/log, result@/tmp/starwhale/cmp/result
   ```

## Evaluate a model

```bash
swcli model eval [OPTIONS] MODEL
```

- This command creates a new job for model evaluation.
- `MODEL` argument is required. The `Model URI` or model working dir path is ok for the `MODEL` argument.
- `model eval` command is beneficial for you to debug ppl/cmp and evaluate models in the standalone instance.
- Options:

    |Option|Alias Option|Required|Type|Default|Description|
    |------|--------|-------|-----------|-----|-----------|
    |`--dataset`||✅|String||one or more dataset uris are ok for evaluation|
    |`--name`||❌|String|""|evaluation job name|
    |`--desc`||❌|String|""|evaluation job description|
    |`--project`|`-p`|❌|String|Selected project|Project URI|
    |`--use-docker`||❌|Boolean|False|Only for standalone instance, use docker environment to run model evaluation|
- Example:

    ```bash
    ❯ swcli model eval . --dataset mnist/version/latest
    😹 local_fuse.json existed, skip render
    🔍 /home/liutianwei/.cache/starwhale/self/dataset/mnist/gv/gvsgemdbhazwknrtmftdgyjzoaygynq.swds/local_fuse.json
    try to import mnist.ppl:MNISTInference@....
    load mnist model, start to inference...
    👏 finish run ppl: PipelineHandler status@/home/liutianwei/.cache/starwhale/self/job/hb/hbsdkzjzgvtgknjxmuzdiolfgz3ti4i/ppl/status, log@/home/liutianwei/.cache/starwhale/self/job/hb/hbsdkzjzgvtgknjxmuzdiolfgz3ti4i/ppl/log, result@/home/liutianwei/.cache/starwhale/self/job/hb/hbsdkzjzgvtgknjxmuzdiolfgz3ti4i/ppl/result
    try to import mnist.ppl:MNISTInference@....
    load mnist model, start to inference...
    👏 finish run cmp: PipelineHandler status@/home/liutianwei/.cache/starwhale/self/job/hb/hbsdkzjzgvtgknjxmuzdiolfgz3ti4i/cmp/status, log@/home/liutianwei/.cache/starwhale/self/job/hb/hbsdkzjzgvtgknjxmuzdiolfgz3ti4i/cmp/log, result@/home/liutianwei/.cache/starwhale/self/job/hb/hbsdkzjzgvtgknjxmuzdiolfgz3ti4i/cmp/result
    7 out of 7 steps finished ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 0:00:05
    👏 success to create job(project id: local/project/self)
    🐦 run cmd to fetch job info: swcli job info hbsdkzjzgvtg
    ```

## List models

```bash
swcli model list [OPTIONS]
```

- This command lists all models in the project.
- Options:

    |Option|Alias Option|Required|Type|Default|Description|
    |------|--------|-------|-----------|-----|-----------|
    |`--project`|`-p`|❌|String|Selected project|Project URI|
    |`--fullname`||❌|Boolean|False|Show fullname of model version|
    |`--show-removed`||❌|Boolean|False|Show removed models|
    |`--page`||❌|Integer|1|Page number for model list|
    |`--size`||❌|Integer|20|Page size for model list|

## Get model info

```bash
swcli model info [OPTIONS] MODEL
```

- This command inspects the model details.
- The `MODEL` argument uses the `Model URI` format so that you can inspect the whole model or a specified-version model.
- Options:

    |Option|Alias Option|Required|Type|Default|Description|
    |------|--------|-------|-----------|-----|-----------|
    |`--fullname`||❌|Boolean|False|Show version fullname|

## Show model history

```bash
swcli model history [OPTIONS] MODEL
```

- This command shows the history of a model and lists all its versions.
- `MODEL` argument uses the `Model URI` format.
- Options:

    |Option|Alias Option|Required|Type|Default|Description|
    |------|--------|-------|-----------|-----|-----------|
    |`--fullname`||❌|Boolean|False|Show version fullname|

- Example:

    ```bash
    ❯ swcli model history mnist --fullname
    ```

## Manage model tags

```bash
swcli model tag [OPTIONS] MODEL TAGS
```

- This command adds or removes tags on a specified model version.
- `MODEL` argument uses the `Model URI` format which must include `/version/{version id}` part.
- You can write one or more `TAG` arguments.
- Options:

    |Option|Alias Option|Required|Type|Default|Description|
    |------|--------|-------|-----------|-----|-----------|
    |`--remove`|`-r`|❌|Boolean|False|Remove tags|
    |`--quiet`|`-q`|❌|Boolean|False|Ignore tag name errors like name duplication, name absence|

- Example:

    ```bash
    ❯ swcli model tag mnist/version/hbtdenjxgm4g test v2
    ```

## Remove a model

```bash
swcli model remove [OPTIONS] MODEL
```

- This command removes a model. You can run `swcli model recover` to recover the removed models.
- The `MODEL` argument uses the `Model URI` format so that you can remove the whole model or a specified-version model.
- Support the short version or tag in `Model URI` format when you remove a model.
- Options:

    |Option|Alias Option|Required|Type|Default|Description|
    |------|--------|-------|-----------|-----|-----------|
    |`--force`|`-f`|❌|Boolean|False|Force to remove model|

- Example:

    ```bash
    ❯ swcli model remove mnist/version/v2
    continue to remove? [y/N]: y
    👏 do successfully
    ```

## Recover a model

```bash
swcli model recover [OPTIONS] MODEL
```

- This command recovers a removed model. You can run `swcli model list --show-removed` to fetch removed models.
- `MODEL` argument uses the `Model URI` format so that you can recover the whole model or a specified-version model.
- Only the full version in `Model URI` format is supported when you recover a model.
- Options:

    |Option|Alias Option|Required|Type|Default|Description|
    |------|--------|-------|-----------|-----|-----------|
    |`--force`|`-f`|❌|Boolean|False|Force to recover model|

- Example:

    ```bash
    ❯ swcli model recover mnist/version/hbtdenjxgm4ggnrtmftdgyjzm43tioi
    👏 do successfully
    ```

## Copy a model

```bash
swcli model copy [OPTIONS] SRC DEST
```

- This command copies a model to another place, either locally or remotely.
`SRC` uses `Model URI`, which can locate an existing model version in standalone or cloud instances.
- `DEST` uses `Project URI`, which implies the storage project in the destination instance. If the `DEST` project has already stored a model with the same name and version, you can set the `--force` argument to force update.
- Today, this command only supports copying a model from the standalone to the cloud or from the cloud to the standalone. `standalone -> standalone` and `cloud -> cloud` are not supported.
- Options:

    |Option|Alias Option|Required|Type|Default|Description|
    |------|--------|-------|-----------|-----|-----------|
    |`--force`|`-f`|❌|Boolean|False|Force to copy model|

- Example: copy a model from the local standalone instance to the remote cloud instance(upload)

    ```bash
    ❯ swcli model copy mnist/version/latest cloud://pre-k8s/project/1
    🚧 start to copy local/project/self/model/mnist/version/latest -> http://console.pre.intra.starwhale.ai/project/1...
    🎳 upload gbstgnlgheydqnrtmftdgyjzpe4tezy.swmp ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 4.9 MB
    👏 copy done.
    ```

- Example: copy a model from the remote cloud instance to the local standalone instance(download)

    ```bash
    ❯ swcli model copy cloud://pre-k8s/project/1/model/mnist/version/gbstgnlgheydqnrtmftdgyjzpe4tezy self --force
    🚧 start to copy http://console.pre.intra.starwhale.ai/project/1/model/mnist/version/gbstgnlgheydqnrtmftdgyjzpe4tezy -> local/project/self...
    🎳 download to /home/liutianwei/.cache/starwhale/self/model/mnist/gb/gbstgnlgheydqnrtmftdgyjzpe4tezy.swmp... ━━ 100% 0… 1
    👏 copy done.
    ```
