{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "139231ed",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/star-whale/starwhale/blob/main/example/notebooks/dataset-sdk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e52fcd8",
   "metadata": {},
   "source": [
    "# 1. Installing Starwhale\n",
    "\n",
    "Starwhale can be installed via `pip` command. By default, Starwhale does not install dependencies for audio and image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77f9a1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip install \"starwhale[all]\"  # install starwhale all dependencies: audio and image\n",
    "# pip install \"starwhale[image]\"   # --> install image dependencies: pillow\n",
    "# pip install \"starwhale[audio]\"   # --> install audio dependencies: soundfile\n",
    "# pip install starwhale     # --> install basic dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35b38e18",
   "metadata": {},
   "source": [
    "# 2.  Building CIFAR10 Dataset\n",
    "\n",
    "[CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) Dataset is an image dataset that includes 60000 32*32 color images in 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278a92a1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rm -rf data && mkdir data\n",
    "curl -o data/cifar.tar.gz https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz \n",
    "tar -xzf data/cifar.tar.gz -C data\n",
    "rm -rf data/cifar.tar.gz\n",
    "ls data/cifar-10-batches-py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c692f01d",
   "metadata": {},
   "source": [
    "## 2.2 Building Starwhale Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bd77065",
   "metadata": {},
   "source": [
    "### 2.2.1 Creating dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d022b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from starwhale import dataset\n",
    "\n",
    "ds = dataset(\"cifar10\", create=\"empty\")\n",
    "print(ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f03b44d2",
   "metadata": {},
   "source": [
    "### 2.2.2 Loading original dataset content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bc890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = Path(os.path.abspath('')) / \"data\" / \"cifar-10-batches-py\"\n",
    "meta = pickle.load((root_dir / \"batches.meta\").open(\"rb\"))\n",
    "train_data_contents = [pickle.load((root_dir /f\"data_batch_{i}\").open(\"rb\"), encoding=\"bytes\")  for i in range(1, 6)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71b5e5b6",
   "metadata": {},
   "source": [
    "### 2.2.3 Appending to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a8e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image as PILImage\n",
    "from starwhale import Image, MIMEType\n",
    "\n",
    "for content in train_data_contents:\n",
    "    for data, label, filename in zip(content[b\"data\"], content[b\"labels\"], content[b\"filenames\"]):\n",
    "        image_array = data.reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "        image_bytes = io.BytesIO()\n",
    "        PILImage.fromarray(image_array).save(image_bytes, format=\"PNG\")\n",
    "\n",
    "        image_data = Image(fp=image_bytes.getvalue(), display_name=filename.decode(), shape=image_array.shape, mime_type=MIMEType.PNG)\n",
    "        ds.append({\"label\": label, \"display_name\": meta[\"label_names\"][label], \"image\": image_data})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bff86f1",
   "metadata": {},
   "source": [
    "### 2.2.4 Commit and close dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ba877",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.commit()\n",
    "ds.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9b1c30e",
   "metadata": {},
   "source": [
    "## 2.3 Using swcli to find CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee150f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!swcli dataset list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38944236",
   "metadata": {},
   "source": [
    "# 3. Loading Starwhale Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c021bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from starwhale import dataset\n",
    "\n",
    "ds = dataset(\"cifar10/version/latest\")\n",
    "print(ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4560a9c0",
   "metadata": {},
   "source": [
    "## 3.1 Showing dataset summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5603e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset summary\n",
    "ds.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdb3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset rows count\n",
    "len(ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40ec3d69",
   "metadata": {},
   "source": [
    "## 3.2 Fetching data rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff64f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first dataset row\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd675fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pillow object\n",
    "ds[0].features.image.to_pil()\n",
    "# or ds[0].features[\"image\"].to_pil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator for dataset\n",
    "rows = list(ds[:10])\n",
    "len(rows)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04324ee0",
   "metadata": {},
   "source": [
    "## 3.3 To Pytorch Dataset\n",
    "\n",
    "Starwhale Dataset can be converted into Pytorch dataset automatically. Before code execution, we should install Pytorch lib via pip command. Pytorch is not the Starwhale package dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab47129",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_ds = ds.to_pytorch()\n",
    "print(torch_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79658140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "torch_loader = torch.utils.data.DataLoader(torch_ds, batch_size=5)\n",
    "item = next(iter(torch_loader))\n",
    "print(item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc99307c",
   "metadata": {},
   "source": [
    "## 3.4 To Tensorflow Dataset\n",
    "Starwhale Dataset can be converted into Tensorflow dataset automatically. Before code execution, we should install Pytorch lib via tensorflow command. Tensorflow is not the Starwhale package dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3e3260",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bae770",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_ds = ds.to_tensorflow()\n",
    "print(tf_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfaff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "batch_ds = tf_ds.batch(5, drop_remainder=True)\n",
    "items = list(batch_ds.take(2))\n",
    "print(items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74eb89cb",
   "metadata": {},
   "source": [
    "üç∫ Congratulations! You just learned to use starwhale sdk to build and load dataset. üëç"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starwhale",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:15:33) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "44f309826dc86d485633ae8f49ea70651a134501b3cf4f8233b66a54380b4a5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
